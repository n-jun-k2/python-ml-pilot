# 機械学習ノート

- [ONNX model zoo](https://github.com/onnx/models)




## 機械学習の基礎

### 学習アルゴリズムとは
---
性能指標Pで測定されるタスクTにおける性能が経験Eにより改善される場合、そのタスクTのクラス及び性能指標Pに関して経験Eから学習すると言われている。

#### **タスクT**
---
- 分類(classification)
- 欠損値のある入力の分類(classification with missing inputs)
- 回帰(regression)
- 転写(transcription)
- 機械翻訳
- 構造出力(structured output)
- 異常検知(anomaly detection)
- 合成とサンプリング(synthesis and sampling)
- 欠損値補完(imputation of missing values)
- ノイズ除去(denoising)
- 密度推定(density estimation)

#### **性能指標P**
---
性能指標Pは実行されるタスクTに固有である。

- 分類：モデルの精度(accuracy)or誤差率(error rate)
- 欠損値のある入力の分類：モデルの精度(accuracy)or誤差率(error rate)
- 転写：モデルの精度(accuracy)or誤差率(error rate)
- 密度推定：測定基準を用いて各事例に対する連続値のスコアをモデルに与える。例）対数確率の平均

未知のデータに対してアルゴリズムがどの程度機能するかを知りたい。
その為、学習データとは異なるテストデータを用いて性能指標を評価する

#### **経験E**
---
学習過程においてどのような経験を獲得できるかによって
``教師無し``と``教師あり``に分類できる。

- 教師なし：多くの特徴量を含むデータ集合からデータ集合構造の有益な特性を学習する。
    > 確率ベクトルxの事例を観察し、確率分布p(x)やその分布の重症な特性を明示的もしくは暗黙的に学習する。

- 教師あり：特徴量を含むデータ集合を利用するが、各事例はラベルや目標と関連付けされている。
    > 確率ベクトルxとそれに関連付けられた数値もしくはベクトルyの事例を観察し、p(y|x)を推定することでxからyを予測できるように学習する。

## **容量、過剰適合、過少適合**
---
機械学習の中心的な課題は、これまで見たことのない新たな入力に対しても
アルゴリズムは良い性能を発揮しなければならないということである。これを汎化と呼ぶ。


### **最適化問題と機械学習の違い**
---
最適化問題は、訓練集合を使用し学習させたモデルの``訓練誤差``を指標にその誤差を小さくするという事が目的であるが、
機械学習では、汎化誤差（新しい入力に対する五さの期待値）も小さくしたいという点で機械学習と最適化問題は異なる。

### **データ生成過程**
---
訓練データとテストデータはデータ生成過程と呼ばれるデータ集合の確率分布から生成される。
通常は``i.i.d.仮定``と総称される一連の仮定を置く、その過程とは、各データ集合の事例が互いに独立であり、
また訓練集合とテスト集合が``同一の分布に従う``、すなわち相互に同じ確率分布から抽出されるというものである。

### **データ生成分布**
---
i.i.d.仮定により、単一の事例に対する確率分布を用いてデータ生成過程を記述できる。
そして同じ確率分布を用いて、全ての教師事例とテスト事例を生成する。

この潜在的な分布はデータ生成分布と呼ばれ、Pdataと表される。

機械学習アルゴリズムがどの程度上手く動作するかを決定する要素は以下に挙げる能力である。

1. **訓練誤差を小さくする**
2. **訓練誤差とテスト誤差の差を小さくする**

この2つは以下に相当する。
1. 過少適合：訓練集合において十分に小さい誤差が得られない場合。
2. 過剰適合：訓練誤差とテスト誤差が大きい場合。

モデルの過少適合・過剰適合のし易さは、モデルの**容量**で制御できる。

### **モデルの容量**
---

> 容量とはモデルが多様な関数に適合する能力の事。

- モデル容量が小さい場合、訓練集合を適合させるのが難しい（過少適合）
- モデル容量が大きい場合、テスト集合に意味をなさない訓練集合の特性を記憶してしまう。（過剰適合）

### **容量の制御**

- **仮説空間**
  -  アルゴリズムが解として選択できる関数空間の集合の事

### **パラメトリックモデル・ノンパラメトリックモデル**

- パラメトリックモデル
  - 関数の形を決めた上で関数のパラメータを設定することで、データにフィッティングさせる手法を用いたモデルのことです。


- ノンパラメトリックモデル
  - 予め関数の形を決めずにデータにフィッティングさせる手法を用いたモデルのことです。


# ノーフリーランチ定理

> コスト関数の極値を探索するあらゆるアルゴリズムは、全ての可能なコスト関数に適用した結果を平均すると同じ性能となる (wiki参照)

機械学習では、純粋な理論的推論で使われる完全に確実な規則ではなく、
確率的な規則のみを提供することによってこの問題を部分的に回避している

機械学習では、関係するほとんどの要素において、ほぼ正しい規則の発見が約束される。

# 正則化

モデルを学習する際に、その仮説空間内のある解を他の解より優先させることができる。
これはどちらも解であるが、その一方が優先される事。

優先されない解は、優先されている解よりも訓練データに対して、良く適合されている場合のみ選ばれる。

他の解に対して優先度を表現する方法をまとめて、**正則化**と呼びます。


## 点推定量

> 観測データに基づいて未知量に対する良好な推定（推定量）と見なせる値（統計量）を計算する手法とその結果を言う。平均値・中央値・最頻値などが用いられる。尤度関数の最頻値で推定する場合、事前分布がない場合を最尤推定、事前分布がある場合を最大事後確率推定という。
通常、推定値は記号の上に「＾」をつける。(wiki)

## 関数推定

> 
